{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Use webscraping to gather list of hockey teams and their information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "I using several python libraries for this project:\n",
    "- pandas\n",
    "- request\n",
    "- BeautifulSoup\n",
    "- html5lib\n",
    "- lxml\n",
    "- urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html5lib\n",
    "import lxml\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data Using Web Scraping\n",
    "The book list webpage https://www.scrapethissite.com/ provide information about list of hockey teams as well as their Team Name, Year, Wins, Losses, and etc. We will scrape the data for all teams in the list and store it in csv files. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webpage Contents\n",
    "Gather the contents of the webpage and convert into text format using the `requests` library and assign it to variable `html_data`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data\n",
    "Using the contents and `beautiful soup` load the data from webpage into `pandas` dataframe.\n",
    "\n",
    "Using BeautifulSoup parse the contents of the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hockey_teams_data dataframe will be used for store the data, with the columns as well as displayed below\n",
    "hockey_teams_data = pd.DataFrame(columns=[\"Team Name\", \"Year\", \"Wins\", \"Losses\", \"OT Losses\", \"Win %\", \"Goals For (GF)\", \"Goals Against (GA)\", \"+ / -\"])\n",
    "\n",
    "# Looping to find the next page we will scrape\n",
    "for i in range(1, 3):\n",
    "    url = 'https://www.scrapethissite.com/pages/forms/?page_num='+str(i)\n",
    "    html_data = requests.get(url).text\n",
    "    \n",
    "    soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Check wheteher the loop works well or not by displaying the link of each page\n",
    "    # pagination = soup.find('ul', class_=\"pagination\")\n",
    "    # np = pagination.find('a').get(\"href\")\n",
    "    # full_np = \"https://www.scrapethissite.com\" + np\n",
    "    # print(full_np)    \n",
    "\n",
    "\n",
    "\n",
    "    # In case need to replace all element \"th\" into \"td\" to make scrap all table data more easier, run this code\n",
    "    # new_tags_string = [\"Team Name\", \"Year\", \"Wins\", \"Losses\", \"OT Losses\", \"Win %\", \"Goals For (GF)\", \"Goals Against (GA)\", \"+ / -\"]\n",
    "    # for replace in table.find_all('th'):\n",
    "    #     new_tags = soup.new_tag('td')\n",
    "    #     replace.replace_with(new_tags)\n",
    "    #     for n in new_tags_string:\n",
    "    #         new_tags.string = n\n",
    "    #         break\n",
    "    #     del(new_tags_string[0])\n",
    "\n",
    "\n",
    "    # Remove table head since i don't need it right now, i'll add the table head later with pandas\n",
    "    remove_tag = table.find('tr') #<---- find only the first element 'tr' in table\n",
    "    remove_tag.decompose() #<---- remove that element\n",
    "\n",
    "    for row in table.find_all('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        team_name = cols[0].text.strip()\n",
    "        year = cols[1].text.strip()\n",
    "        wins = cols[2].text.strip()\n",
    "        losses = cols[3].text.strip()\n",
    "        ot_losses = cols[4].text.strip()\n",
    "        win_rate = cols[5].text.strip()\n",
    "        gf = cols[6].text.strip()\n",
    "        ga = cols[7].text.strip()\n",
    "        diff = cols[8].text.strip()\n",
    "        hockey_teams_data = hockey_teams_data.append({\"Team Name\": team_name, \"Year\": year, \"Wins\": wins, \"Losses\": losses, \"OT Losses\": ot_losses, \"Win %\": win_rate, \"Goals For (GF)\": gf, \"Goals Against (GA)\": ga, \"+ / -\": diff}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hockey_teams_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case need to replace all element \"th\" into \"td\" to make scrap all table data more easier, run this code\n",
    "# new_tags_string = [\"Team Name\", \"Year\", \"Wins\", \"Losses\", \"OT Losses\", \"Win %\", \"Goals For (GF)\", \"Goals Against (GA)\", \"+ / -\"]\n",
    "\n",
    "# for replace in table.find_all('th'):\n",
    "#     new_tags = soup.new_tag('td')\n",
    "#     replace.replace_with(new_tags)\n",
    "#     for n in new_tags_string:\n",
    "#         new_tags.string = n\n",
    "#         break\n",
    "#     del(new_tags_string[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove table head since i don't need it right now, i'll add the table head later with pandas\n",
    "# remove_tag = table.find('tr') #<---- find only the first element 'tr' in table\n",
    "# remove_tag.decompose() #<---- remove that element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hockey_teams_data = pd.DataFrame(columns=[\"Team Name\", \"Year\", \"Wins\", \"Losses\", \"OT Losses\", \"Win %\", \"Goals For (GF)\", \"Goals Against (GA)\", \"+ / -\"])\n",
    "\n",
    "# for row in table.find_all('tr'):\n",
    "#     cols = row.find_all('td')\n",
    "#     team_name = cols[0].text.strip()\n",
    "#     year = cols[1].text.strip()\n",
    "#     wins = cols[2].text.strip()\n",
    "#     losses = cols[3].text.strip()\n",
    "#     ot_losses = cols[4].text.strip()\n",
    "#     win_rate = cols[5].text.strip()\n",
    "#     gf = cols[6].text.strip()\n",
    "#     ga = cols[7].text.strip()\n",
    "#     diff = cols[8].text.strip()\n",
    "#     hockey_teams_data = hockey_teams_data.append({\"Team Name\": team_name, \"Year\": year, \"Wins\": wins, \"Losses\": losses, \"OT Losses\": ot_losses, \"Win %\": win_rate, \"Goals For (GF)\": gf, \"Goals Against (GA)\": ga, \"+ / -\": diff}, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
